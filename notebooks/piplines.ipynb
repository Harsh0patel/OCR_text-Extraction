{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-29T18:28:14.982681Z",
     "start_time": "2025-11-29T18:28:12.040451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize PaddleOCR instance\n",
    "from paddleocr import PaddleOCR\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# paddleocr model for detection and extraction of text\n",
    "ocr = PaddleOCR(\n",
    "    use_angle_cls = False,\n",
    "    lang='en',\n",
    "    use_doc_orientation_classify=False,\n",
    "    use_doc_unwarping=False,\n",
    "    text_det_box_thresh=0,\n",
    ")"
   ],
   "id": "e1de6ff1af84e80b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp333\\AppData\\Local\\Temp\\ipykernel_15484\\3447655961.py:7: DeprecationWarning: The parameter `use_angle_cls` has been deprecated and will be removed in the future. Please use `use_textline_orientation` instead.\n",
      "  ocr = PaddleOCR(\n",
      "\u001B[32mCreating model: ('PP-OCRv5_server_det', None)\u001B[0m\n",
      "\u001B[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\hp333\\.paddlex\\official_models\\PP-OCRv5_server_det`.\u001B[0m\n",
      "\u001B[32mCreating model: ('en_PP-OCRv5_mobile_rec', None)\u001B[0m\n",
      "\u001B[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\hp333\\.paddlex\\official_models\\en_PP-OCRv5_mobile_rec`.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T18:23:31.352986Z",
     "start_time": "2025-11-29T18:23:31.342199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def needs_opening(img):\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img.copy()\n",
    "\n",
    "    if len(np.unique(gray)) == 2:  # Already binary\n",
    "        bw = gray\n",
    "    else:\n",
    "        _, bw = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(bw, connectivity=8)\n",
    "    if num_labels < 2:\n",
    "        return False\n",
    "\n",
    "    img_area = bw.shape[0] * bw.shape[1]\n",
    "\n",
    "    small_objects = sum(\n",
    "        1 for area in stats[1:, cv2.CC_STAT_AREA]  # Skip background (index 0)\n",
    "        if area < (img_area * 0.0001)  # Less than 0.01% of image\n",
    "    )\n",
    "    noise_threshold = max(20, num_labels * 0.1)  # At least 20 or 10% of objects\n",
    "    return small_objects > noise_threshold\n",
    "\n",
    "\n",
    "def needs_closing(img):\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img.copy()\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    grad = cv2.morphologyEx(gray, cv2.MORPH_GRADIENT, kernel)\n",
    "    edge_density = np.count_nonzero(edges) / edges.size\n",
    "    grad_std = np.std(grad)\n",
    "\n",
    "    return edge_density > 0.15 or grad_std > 40\n",
    "\n",
    "\n",
    "def needs_dilation(img):\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img.copy()\n",
    "\n",
    "    if len(np.unique(gray)) == 2:\n",
    "        bw = gray\n",
    "    else:\n",
    "        _, bw = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    if np.mean(bw) > 127:\n",
    "        bw = cv2.bitwise_not(bw)\n",
    "    dist = cv2.distanceTransform(bw, cv2.DIST_L2, 5)\n",
    "    text_pixels = dist[dist > 0]\n",
    "\n",
    "    if len(text_pixels) == 0:  # No text found\n",
    "        return False\n",
    "\n",
    "    mean_stroke = np.mean(text_pixels)\n",
    "    median_stroke = np.median(text_pixels)\n",
    "    min_stroke = max(1.5, min(bw.shape) * 0.003)\n",
    "    return mean_stroke < min_stroke or median_stroke < 1.0"
   ],
   "id": "fc5f376325f89bf8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T18:23:34.282354Z",
     "start_time": "2025-11-29T18:23:34.275030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def intelligent_dpi_adjustment(img):\n",
    "    \"\"\"\n",
    "    Complete intelligent DPI adjustment for OCR.\n",
    "    Combines multiple strategies for best results.\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Original dimensions: {w}x{h}\")\n",
    "\n",
    "    # Strategy 1: Check if image is reasonable size\n",
    "    min_dimension = min(w, h)\n",
    "    max_dimension = max(w, h)\n",
    "\n",
    "    # Rule 1: Minimum size check (for very small images)\n",
    "    if max_dimension < 800:\n",
    "        scale = 800 / max_dimension\n",
    "        print(f\"Rule: Image too small, scaling up by {scale:.2f}x\")\n",
    "\n",
    "    # Rule 2: Maximum size check (for very large images)\n",
    "    elif max_dimension > 4000:\n",
    "        scale = 4000 / max_dimension\n",
    "        print(f\"Rule: Image too large, scaling down by {scale:.2f}x\")\n",
    "\n",
    "    # Rule 3: Optimal range (1200-2500px on longest edge)\n",
    "    elif max_dimension < 1200:\n",
    "        scale = 1500 / max_dimension\n",
    "        print(f\"Rule: Upscaling to optimal range ({scale:.2f}x)\")\n",
    "    elif max_dimension > 2500:\n",
    "        scale = 2000 / max_dimension\n",
    "        print(f\"Rule: Downscaling to optimal range ({scale:.2f}x)\")\n",
    "    else:\n",
    "        scale = 1.0\n",
    "        print(f\"Rule: Size already optimal, no scaling needed\")\n",
    "\n",
    "    # Apply scaling\n",
    "    if scale != 1.0:\n",
    "        new_w = int(w * scale)\n",
    "        new_h = int(h * scale)\n",
    "\n",
    "        # Choose best interpolation\n",
    "        if scale > 1.0:\n",
    "            interpolation = cv2.INTER_CUBIC  # Smooth upscaling\n",
    "            print(\"Interpolation: INTER_CUBIC (upscaling)\")\n",
    "        else:\n",
    "            interpolation = cv2.INTER_AREA  # Sharp downscaling\n",
    "            print(\"Interpolation: INTER_AREA (downscaling)\")\n",
    "\n",
    "        img = cv2.resize(img, (new_w, new_h), interpolation=interpolation)\n",
    "        print(f\"Final dimensions: {new_w}x{new_h}\")\n",
    "        print(f\"Equivalent DPI: ~{new_h / 11 * 300:.0f} DPI (assuming 11\\\" height)\")\n",
    "\n",
    "    print(f\"{'='*50}\\n\")\n",
    "    return img"
   ],
   "id": "a58c58d55708916",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T18:27:45.430145Z",
     "start_time": "2025-11-29T18:27:32.046058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#preprocessing pipeline\n",
    "path = \"C:/Users/hp333/Desktop/ocr/Data/Test Data/reverseWaybill-156387426414724544_1.jpg\"\n",
    "img = cv2.imread(path)\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "print(\"height : \", h, \" width : \", w)\n",
    "\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# img = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY, 11, 2)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "img = clahe.apply(gray_img)\n",
    "\n",
    "#smoothing\n",
    "noise_level = np.std(img)\n",
    "print(\"Noise level: \", noise_level)\n",
    "if noise_level > 35:\n",
    "    img = cv2.fastNlMeansDenoising(img, None, h=10, templateWindowSize=7, searchWindowSize=21)\n",
    "    print(\"smoothing done\")\n",
    "elif noise_level > 25:\n",
    "    img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "    print(\"smoothing done\")\n",
    "\n",
    "# sharpening using kernels\n",
    "laplacian_var = cv2.Laplacian(gray_img, cv2.CV_64F).var()\n",
    "print(\"Laplacian variance:\", laplacian_var)\n",
    "\n",
    "# Adaptive threshold based on image size\n",
    "img_size = w * h\n",
    "adaptive_threshold = 100 * (img_size / 1000000)  # Scale with megapixels\n",
    "adaptive_threshold = max(50, min(adaptive_threshold, 500))  # Clamp between 50-500\n",
    "\n",
    "print(f\"Adaptive blur threshold: {adaptive_threshold:.1f}\")\n",
    "\n",
    "if laplacian_var < adaptive_threshold:\n",
    "    print(\"Sharpening applied\")\n",
    "    # Unsharp masking (gentler than direct kernel)\n",
    "    gaussian = cv2.GaussianBlur(img, (0, 0), 2.0)\n",
    "    img = cv2.addWeighted(img, 1.5, gaussian, -0.5, 0)\n",
    "\n",
    "    # Or use your kernel with reduced intensity\n",
    "    # kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]) / 1.5\n",
    "    # img = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "# laplacian_var = cv2.Laplacian(gray_img, cv2.CV_64F).var()\n",
    "# print(\"laplacian var: \", laplacian_var)\n",
    "# if laplacian_var < 100:\n",
    "#     print(\"sharpening done\")\n",
    "#     kernal = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "#     img = cv2.filter2D(img, -1, kernal)\n",
    "\n",
    "#morphological cleanup\n",
    "kernel_size = max(3, min(w, h) // 200)\n",
    "opening_kernel = np.ones((max(3, min(w,h)//300), max(3, min(w,h)//300)), np.uint8)\n",
    "closing_kernel = np.ones((max(5, min(w,h)//150), max(5, min(w,h)//150)), np.uint8)\n",
    "if needs_dilation(img):\n",
    "    print(\"dilation done\")\n",
    "    img = cv2.dilate(img, kernel_size)\n",
    "\n",
    "if needs_opening(img):\n",
    "    print(\"opening done\")\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_OPEN, opening_kernel)\n",
    "\n",
    "if needs_closing(img):\n",
    "    print(\"closing done\")\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, closing_kernel)\n",
    "\n",
    "#DPI adjustments\n",
    "img = intelligent_dpi_adjustment(img)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "# Results\n",
    "cv2.imshow(\"preprocessed image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "c543000395ac26b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height :  2160  width :  3840\n",
      "Noise level:  38.04420779780377\n",
      "smoothing done\n",
      "Laplacian variance: 106.84604515594019\n",
      "Adaptive blur threshold: 500.0\n",
      "Sharpening applied\n",
      "opening done\n",
      "\n",
      "==================================================\n",
      "Original dimensions: 3840x2160\n",
      "Rule: Downscaling to optimal range (0.52x)\n",
      "Interpolation: INTER_AREA (downscaling)\n",
      "Final dimensions: 2000x1125\n",
      "Equivalent DPI: ~30682 DPI (assuming 11\" height)\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T18:28:30.431283Z",
     "start_time": "2025-11-29T18:28:23.069254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run OCR inference on a sample image\n",
    "result = ocr.predict(\n",
    "    input = img)"
   ],
   "id": "e77ed56f025e8b1",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T18:28:31.975120Z",
     "start_time": "2025-11-29T18:28:31.283568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Visualize the results and save the JSON results\n",
    "for res in result:\n",
    "    res.save_to_img(\"output\")\n",
    "    res.save_to_json(\"output\")\n"
   ],
   "id": "16d7ba25bd44ad8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33mThere is not input file name as reference for name of saved result file. So the saved result file would be named with timestamp and random number: `1764440911_7981`.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

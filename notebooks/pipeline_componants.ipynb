{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-30T19:06:33.102239Z",
     "start_time": "2025-11-30T19:06:01.042241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize PaddleOCR instance\n",
    "from paddleocr import PaddleOCR\n",
    "import cv2\n",
    "import numpy as np\n",
    "import regex as re\n",
    "from deskew import determine_skew\n",
    "import os\n",
    "\n",
    "# paddleocr model for detection and extraction of text\n",
    "ocr = PaddleOCR(lang = 'en')"
   ],
   "id": "e1de6ff1af84e80b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp333\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\hp333\\AppData\\Roaming\\Python\\Python311\\site-packages\\paddle\\utils\\cpp_extension\\extension_utils.py:718: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "\u001B[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001B[0m\n",
      "\u001B[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\hp333\\.paddlex\\official_models\\PP-LCNet_x1_0_doc_ori`.\u001B[0m\n",
      "\u001B[32mCreating model: ('UVDoc', None)\u001B[0m\n",
      "\u001B[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\hp333\\.paddlex\\official_models\\UVDoc`.\u001B[0m\n",
      "\u001B[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001B[0m\n",
      "\u001B[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\hp333\\.paddlex\\official_models\\PP-LCNet_x1_0_textline_ori`.\u001B[0m\n",
      "\u001B[32mCreating model: ('PP-OCRv5_server_det', None)\u001B[0m\n",
      "\u001B[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\hp333\\.paddlex\\official_models\\PP-OCRv5_server_det`.\u001B[0m\n",
      "\u001B[32mCreating model: ('en_PP-OCRv5_mobile_rec', None)\u001B[0m\n",
      "\u001B[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\hp333\\.paddlex\\official_models\\en_PP-OCRv5_mobile_rec`.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T19:06:33.123148Z",
     "start_time": "2025-11-30T19:06:33.112249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def needs_opening(img):\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img.copy()\n",
    "\n",
    "    if len(np.unique(gray)) == 2:  # Already binary\n",
    "        bw = gray\n",
    "    else:\n",
    "        _, bw = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(bw, connectivity=8)\n",
    "    if num_labels < 2:\n",
    "        return False\n",
    "\n",
    "    img_area = bw.shape[0] * bw.shape[1]\n",
    "\n",
    "    small_objects = sum(\n",
    "        1 for area in stats[1:, cv2.CC_STAT_AREA]  # Skip background (index 0)\n",
    "        if area < (img_area * 0.0001)  # Less than 0.01% of image\n",
    "    )\n",
    "    noise_threshold = max(20, num_labels * 0.1)  # At least 20 or 10% of objects\n",
    "    return small_objects > noise_threshold\n",
    "\n",
    "\n",
    "def needs_closing(img):\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img.copy()\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    grad = cv2.morphologyEx(gray, cv2.MORPH_GRADIENT, kernel)\n",
    "    edge_density = np.count_nonzero(edges) / edges.size\n",
    "    grad_std = np.std(grad)\n",
    "\n",
    "    return edge_density > 0.15 or grad_std > 40\n",
    "\n",
    "\n",
    "def needs_dilation(img):\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img.copy()\n",
    "\n",
    "    if len(np.unique(gray)) == 2:\n",
    "        bw = gray\n",
    "    else:\n",
    "        _, bw = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    if np.mean(bw) > 127:\n",
    "        bw = cv2.bitwise_not(bw)\n",
    "    dist = cv2.distanceTransform(bw, cv2.DIST_L2, 5)\n",
    "    text_pixels = dist[dist > 0]\n",
    "\n",
    "    if len(text_pixels) == 0:  # No text found\n",
    "        return False\n",
    "\n",
    "    mean_stroke = np.mean(text_pixels)\n",
    "    median_stroke = np.median(text_pixels)\n",
    "    min_stroke = max(1.5, min(bw.shape) * 0.003)\n",
    "    return mean_stroke < min_stroke or median_stroke < 1.0"
   ],
   "id": "fc5f376325f89bf8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T19:06:33.135532Z",
     "start_time": "2025-11-30T19:06:33.128153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def intelligent_dpi_adjustment(img):\n",
    "    \"\"\"\n",
    "    Complete intelligent DPI adjustment for OCR.\n",
    "    Combines multiple strategies for best results.\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Original dimensions: {w}x{h}\")\n",
    "\n",
    "    # Strategy 1: Check if image is reasonable size\n",
    "    min_dimension = min(w, h)\n",
    "    max_dimension = max(w, h)\n",
    "\n",
    "    # Rule 1: Minimum size check (for very small images)\n",
    "    if max_dimension < 800:\n",
    "        scale = 800 / max_dimension\n",
    "        print(f\"Rule: Image too small, scaling up by {scale:.2f}x\")\n",
    "\n",
    "    # Rule 2: Maximum size check (for very large images)\n",
    "    elif max_dimension > 4000:\n",
    "        scale = 4000 / max_dimension\n",
    "        print(f\"Rule: Image too large, scaling down by {scale:.2f}x\")\n",
    "\n",
    "    # Rule 3: Optimal range (1200-2500px on longest edge)\n",
    "    elif max_dimension < 1200:\n",
    "        scale = 1500 / max_dimension\n",
    "        print(f\"Rule: Upscaling to optimal range ({scale:.2f}x)\")\n",
    "    elif max_dimension > 2500:\n",
    "        scale = 2000 / max_dimension\n",
    "        print(f\"Rule: Downscaling to optimal range ({scale:.2f}x)\")\n",
    "    else:\n",
    "        scale = 1.0\n",
    "        print(f\"Rule: Size already optimal, no scaling needed\")\n",
    "\n",
    "    # Apply scaling\n",
    "    if scale != 1.0:\n",
    "        new_w = int(w * scale)\n",
    "        new_h = int(h * scale)\n",
    "\n",
    "        # Choose best interpolation\n",
    "        if scale > 1.0:\n",
    "            interpolation = cv2.INTER_CUBIC  # Smooth upscaling\n",
    "            print(\"Interpolation: INTER_CUBIC (upscaling)\")\n",
    "        else:\n",
    "            interpolation = cv2.INTER_AREA  # Sharp downscaling\n",
    "            print(\"Interpolation: INTER_AREA (downscaling)\")\n",
    "\n",
    "        img = cv2.resize(img, (new_w, new_h), interpolation=interpolation)\n",
    "        print(f\"Final dimensions: {new_w}x{new_h}\")\n",
    "        print(f\"Equivalent DPI: ~{new_h / 11 * 300:.0f} DPI (assuming 11\\\" height)\")\n",
    "\n",
    "    print(f\"{'='*50}\\n\")\n",
    "    return img"
   ],
   "id": "a58c58d55708916",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T19:07:53.985792Z",
     "start_time": "2025-11-30T19:07:42.669015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#preprocessing pipeline\n",
    "path = \"C:/Users/hp333/Desktop/ocr/Data/reverseWaybill-156387426414724544_1.jpg\"\n",
    "img = cv2.imread(path)\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "print(\"height : \", h, \" width : \", w)\n",
    "\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "angle = determine_skew(gray_img)\n",
    "(h, w) = gray_img.shape\n",
    "M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1)\n",
    "deskewed = cv2.warpAffine(gray_img, M, (w, h), borderMode=cv2.BORDER_REPLICATE)\n",
    "# img = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY, 11, 2)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "img = clahe.apply(gray_img)\n",
    "\n",
    "#smoothing\n",
    "noise_level = np.std(img)\n",
    "print(\"Noise level: \", noise_level)\n",
    "if noise_level > 35:\n",
    "    img = cv2.fastNlMeansDenoising(img, None, h=12, templateWindowSize=7, searchWindowSize=21)\n",
    "    print(\"smoothing done\")\n",
    "elif noise_level > 25:\n",
    "    img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "    print(\"smoothing done\")\n",
    "\n",
    "# sharpening using kernels\n",
    "laplacian_var = cv2.Laplacian(gray_img, cv2.CV_64F).var()\n",
    "print(\"Laplacian variance:\", laplacian_var)\n",
    "\n",
    "# Adaptive threshold based on image size\n",
    "img_size = w * h\n",
    "adaptive_threshold = 100 * (img_size / 1000000)  # Scale with megapixels\n",
    "adaptive_threshold = max(50, min(adaptive_threshold, 500))  # Clamp between 50-500\n",
    "\n",
    "print(f\"Adaptive blur threshold: {adaptive_threshold:.1f}\")\n",
    "\n",
    "if laplacian_var < adaptive_threshold:\n",
    "    print(\"Sharpening applied\")\n",
    "    # Unsharp masking (gentler than direct kernel)\n",
    "    gaussian = cv2.GaussianBlur(img, (0, 0), 2.0)\n",
    "    img = cv2.addWeighted(img, 1.5, gaussian, -0.5, 0)\n",
    "\n",
    "#morphological cleanup\n",
    "kernel_size = max(3, min(w, h) // 200)\n",
    "opening_kernel = np.ones((max(3, min(w,h)//300), max(3, min(w,h)//300)), np.uint8)\n",
    "closing_kernel = np.ones((max(5, min(w,h)//150), max(5, min(w,h)//150)), np.uint8)\n",
    "if needs_dilation(img):\n",
    "    print(\"dilation done\")\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))\n",
    "    img = cv2.dilate(img, kernel)\n",
    "    # img = cv2.dilate(img, kernel_size)\n",
    "\n",
    "if needs_opening(img):\n",
    "    print(\"opening done\")\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_OPEN, opening_kernel)\n",
    "\n",
    "if needs_closing(img):\n",
    "    print(\"closing done\")\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, closing_kernel)\n",
    "\n",
    "#DPI adjustments\n",
    "img = intelligent_dpi_adjustment(img)\n",
    "final_image = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# Results\n",
    "cv2.imshow(\"preprocessed image\", final_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "c543000395ac26b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height :  2160  width :  3840\n",
      "Noise level:  38.04420779780377\n",
      "smoothing done\n",
      "Laplacian variance: 106.84604515594019\n",
      "Adaptive blur threshold: 500.0\n",
      "Sharpening applied\n",
      "opening done\n",
      "\n",
      "==================================================\n",
      "Original dimensions: 3840x2160\n",
      "Rule: Downscaling to optimal range (0.52x)\n",
      "Interpolation: INTER_AREA (downscaling)\n",
      "Final dimensions: 2000x1125\n",
      "Equivalent DPI: ~30682 DPI (assuming 11\" height)\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T19:08:12.873147Z",
     "start_time": "2025-11-30T19:08:02.764854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run OCR inference on a sample image\n",
    "result = ocr.predict(\n",
    "    input = final_image)"
   ],
   "id": "e77ed56f025e8b1",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T14:30:44.841190Z",
     "start_time": "2025-11-30T14:30:44.828919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "def text_from_json(json_data):\n",
    "    \"\"\"\n",
    "    Extract and fix barcode text directly from PaddleOCR JSON output\n",
    "    No need to run OCR again!\n",
    "    \"\"\"\n",
    "    # Parse JSON if it's a string\n",
    "    if isinstance(json_data, str) and os.path.isfile(json_data):\n",
    "        with open(json_data, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "    else:\n",
    "        # Otherwise treat the string as raw JSON text\n",
    "        data = json.loads(json_data) if isinstance(json_data, str) else json_data\n",
    "\n",
    "    # Get all recognized texts and their scores\n",
    "    rec_texts = data.get('rec_texts', [])\n",
    "    rec_scores = data.get('rec_scores', [])\n",
    "    rec_boxes = data.get('rec_boxes', [])\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Process each detected text\n",
    "    for i, text in enumerate(rec_texts):\n",
    "        confidence = rec_scores[i] if i < len(rec_scores) else 0.0\n",
    "        bbox = rec_boxes[i] if i < len(rec_boxes) else None\n",
    "\n",
    "        # Try to fix underscore pattern\n",
    "        fixed_text = fix_underscore_pattern(rec_texts[i])\n",
    "\n",
    "        if fixed_text:\n",
    "            results.append({\n",
    "                'original': text,\n",
    "                'fixed': fixed_text,\n",
    "                'confidence': confidence,\n",
    "                'bbox': bbox\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "def fix_underscore_pattern(text):\n",
    "    \"\"\"\n",
    "    Fix missing underscores in barcode text\n",
    "    Expected pattern: 156381A26414724544_1_whl\n",
    "    Format: [alphanumeric sequence]_[digit]_[letters]\n",
    "    \"\"\"\n",
    "    # Remove all spaces first\n",
    "    text_no_spaces = text.replace(' ', '')\n",
    "\n",
    "    # If already has underscores in correct pattern, return as is\n",
    "    if re.match(r'^[0-9A-Z]+_\\d+_[a-zA-Z]+$', text_no_spaces, re.IGNORECASE):\n",
    "        return text_no_spaces\n",
    "\n",
    "    # Pattern 1: Long alphanumeric + digit + letters (156381A26414724544 1 whl)\n",
    "    # Expected: XXXXXXXXXXXX_X_XXX\n",
    "    pattern1 = r'^([0-9A-Z]{10,})\\s*(\\d{1,2})\\s*([a-zA-Z]{2,5})$'\n",
    "    match = re.match(pattern1, text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return f\"{match.group(1)}_{match.group(2)}_{match.group(3)}\"\n",
    "\n",
    "    # Pattern 2: If OCR merged everything without spaces\n",
    "    # Try to split based on length (assuming 18 chars + 1 digit + 3 letters)\n",
    "    pattern2 = r'^([0-9A-Z]{14,20})(\\d{1,2})([a-zA-Z]{2,5})$'\n",
    "    match = re.match(pattern2, text_no_spaces, re.IGNORECASE)\n",
    "    if match:\n",
    "        return f\"{match.group(1)}_{match.group(2)}_{match.group(3)}\"\n",
    "\n",
    "    # Pattern 3: Only one underscore present (156381A26414724544_1whl or 156381A264147245441_whl)\n",
    "    if text.count('_') == 1:\n",
    "        # Case: XXXXX_Xwhl (missing second underscore)\n",
    "        pattern3a = r'^([0-9A-Z]+)_(\\d{1,2})([a-zA-Z]{2,5})$'\n",
    "        match = re.match(pattern3a, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return f\"{match.group(1)}_{match.group(2)}_{match.group(3)}\"\n",
    "\n",
    "        # Case: XXXXX1_whl (missing first underscore)\n",
    "        pattern3b = r'^([0-9A-Z]+?)(\\d{1,2})_([a-zA-Z]{2,5})$'\n",
    "        match = re.match(pattern3b, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return f\"{match.group(1)}_{match.group(2)}_{match.group(3)}\"\n",
    "\n",
    "    # Pattern 4: Has spaces that should be underscores\n",
    "    # Replace spaces with underscores if text looks like barcode format\n",
    "    if re.match(r'^[0-9A-Z\\s]+\\d+\\s+[a-zA-Z]+$', text, re.IGNORECASE):\n",
    "        # Split by space and reconstruct\n",
    "        parts = text.split()\n",
    "        if len(parts) >= 3:\n",
    "            # Last part is letters, second last is digit(s)\n",
    "            return '_'.join(parts)\n",
    "\n",
    "    return None"
   ],
   "id": "9a06c8ae1e91bb87",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T14:37:46.818663Z",
     "start_time": "2025-11-30T14:37:46.330216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Visualize the results and save the JSON results\n",
    "temp = 1\n",
    "valid_results = []\n",
    "output_dir = \"../results/output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "for res in result:\n",
    "    image = res.save_to_img(save_dir = output_dir, file_name = f\"result_img_{temp}.png\")\n",
    "    # out_path = os.path.join(output_dir, f\"result_img_{temp}.png\")\n",
    "    # cv2.imwrite(out_path, res.img)\n",
    "    json_file = res.save_to_json(save_dir = output_dir, file_name = f\"result_json_{temp}.json\")\n",
    "    # out_path = os.path.join(output_dir, f\"result_json_{temp}.json\")\n",
    "    # cv2.imwrite(out_path, res.json)\n",
    "    temp += 1"
   ],
   "id": "16d7ba25bd44ad8",
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'imwrite'\n> Overload resolution failed:\n>  - img is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'img'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31merror\u001B[39m                                     Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m result:\n\u001B[32m      7\u001B[39m     \u001B[38;5;66;03m# image = res.save_to_img(save_dir = output_dir, file_name = f\"result_img_{temp}.png\")\u001B[39;00m\n\u001B[32m      8\u001B[39m     out_path = os.path.join(output_dir, \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mresult_img_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtemp\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.png\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m     \u001B[43mcv2\u001B[49m\u001B[43m.\u001B[49m\u001B[43mimwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mres\u001B[49m\u001B[43m.\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m \n\u001B[32m     10\u001B[39m     \u001B[38;5;66;03m# json_file = res.save_to_json(save_dir = output_dir, file_name = f\"result_json_{temp}.json\")\u001B[39;00m\n\u001B[32m     11\u001B[39m     out_path = os.path.join(output_dir, \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mresult_json_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtemp\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.json\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31merror\u001B[39m: OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'imwrite'\n> Overload resolution failed:\n>  - img is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'img'\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T14:41:24.239061Z",
     "start_time": "2025-11-30T14:41:24.152431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = text_from_json(result)\n",
    "# Expected pattern: [long alphanumeric]_[1-2 digits]_[2-5 letters]\n",
    "expected_pattern = r'^[0-9A-Z]{14,20}_\\d{1,2}_[a-zA-Z]{2,5}$'\n",
    "\n",
    "for result in results:\n",
    "    fixed_text = result['fixed']\n",
    "    if fixed_text and re.match(expected_pattern, fixed_text, re.IGNORECASE):\n",
    "        valid_results.append(result)\n",
    "print(valid_results)"
   ],
   "id": "2165459e2e369b41",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m results = \u001B[43mextract_barcode_text_from_json\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[38;5;66;03m# Expected pattern: [long alphanumeric]_[1-2 digits]_[2-5 letters]\u001B[39;00m\n\u001B[32m      3\u001B[39m expected_pattern = \u001B[33mr\u001B[39m\u001B[33m'\u001B[39m\u001B[33m^[0-9A-Z]\u001B[39m\u001B[33m{\u001B[39m\u001B[33m14,20}_\u001B[39m\u001B[33m\\\u001B[39m\u001B[33md\u001B[39m\u001B[33m{\u001B[39m\u001B[33m1,2}_[a-zA-Z]\u001B[39m\u001B[33m{\u001B[39m\u001B[33m2,5}$\u001B[39m\u001B[33m'\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 16\u001B[39m, in \u001B[36mextract_barcode_text_from_json\u001B[39m\u001B[34m(json_data)\u001B[39m\n\u001B[32m     13\u001B[39m     data = json.loads(json_data) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(json_data, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m json_data\n\u001B[32m     15\u001B[39m \u001B[38;5;66;03m# Get all recognized texts and their scores\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m rec_texts = \u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m(\u001B[33m'\u001B[39m\u001B[33mrec_texts\u001B[39m\u001B[33m'\u001B[39m, [])\n\u001B[32m     17\u001B[39m rec_scores = data.get(\u001B[33m'\u001B[39m\u001B[33mrec_scores\u001B[39m\u001B[33m'\u001B[39m, [])\n\u001B[32m     18\u001B[39m rec_boxes = data.get(\u001B[33m'\u001B[39m\u001B[33mrec_boxes\u001B[39m\u001B[33m'\u001B[39m, [])\n",
      "\u001B[31mAttributeError\u001B[39m: 'list' object has no attribute 'get'"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T13:09:32.620295Z",
     "start_time": "2025-11-30T13:09:30.566043Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4,
   "source": [
    "path = \"/Data/reverseWaybill-156387426414724544_1.jpg\"\n",
    "img = cv2.imread(path)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "angle = determine_skew(gray)\n",
    "(h, w) = gray.shape\n",
    "M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1)\n",
    "deskewed = cv2.warpAffine(gray, M, (w, h), borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "cv2.imwrite(\"deskewed.jpg\", deskewed)\n"
   ],
   "id": "601d93cacd69e54a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
